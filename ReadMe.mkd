
# 高校信息爬虫

本来想爬取各大高校招生信息（截止日期、 学费、 GPA要求、 外语要求、 GRE要求、 成绩单认证、 存款证明）， 但学校太多， 链接起名各异，网页内部数据组织方式各异， 无法通过设定规则来使用程序爬取、解析。人工处理则太多。

推荐两个网站 

https://yocket.in/  [yocket](https://yocket.in/)

申请方 [申请方](https://www.applysquare.com/cn/)

前者特别不错， 还有不少录取数据。

自己弄的网站

[专业库址](https://www.zhimind.com/oversea/college.html)

因为爬虫搞不出来~~~手工填太麻烦， 申请方是爬虫爬的数据？ 厉害了。


# 大学库

收集了 若干大学信息（其实也就是部分排名和名字而已，而且还是直接爬了别人的，而不是爬了USNEWS）, 在 [大学库](https://www.zhimind.com/oversea/college.html)

# 专业招生信息库

收集了 一些大学（因为是人工，个人成绩太烂，名校就没去收集）信息， 学费、申请截止日期（国际学生）、外语要求、是否需要认证、推荐信、存款证明等, 在 [专业库](https://www.zhimind.com/oversea/major.html)

# 教授研究方向信息库

（将）用爬虫收集 一些大学教授研究方向、是否在招生等信息， 半人工在于需要提供院系faculty的目录页及第一个有链接的教授的链接， 数据准确度则全看那些教授有没有自己主页、且格式是否规范了， 整体来说不好爬， 需要自然语言处理的感觉。 在 [研究方向库](https://www.zhimind.com/oversea/research.html)

速度也比较慢、 数据错误很高——在没有先导知识（知识库）的情况下，强行爬，不仅没法 研究方向能正确找到， 连人名都搞不定， 比如某些学校的链接文字不是对应教授的名字， 就暂时没法获得人名， 毕竟各学校的网页标签不相同——突然想到，我可以再加一个空，再拿到一个教授的名字就能知道名字在哪类标签下了~~~

但研究方向(research interests)的匹配上还非常困难，不仅很容易把多余信息搞进来， 也很难正确处理到位。 比如  image and video processing 和 machine learning and artificial intelligence 的AND 就难搞了， 目前我采取的是替换所有的 and， 然后分开， image 这种单词丢掉。


# TODO

1. 更准确的专业分类，我想前期难免会漏一些专业， 每次都写 html文件和 JS里的变量可不好。所以又是一项参数
2. 计算机研究方向整理， 之后用研究方向匹配。


# 更新记录

## 20170929

自己终于有点好消息， 庆祝！

可以安心来把这块做更好了。首先就是考虑是否把它单独弄成一个网站（不花钱买新域名，只是在服务器上另起一个 flask程序）， 不过想想，算了~~~就是调试时程序比较臃肿一点、启动慢一点而已。

不过那个测试肯定还是需要的，不然， 自己改动后，哪里出错都不知道， 需要拿原数据来做测试，另外 JS怎么测？用 sele什么来着， 另外怎么多线程加快速度， 都是问题， 现在是有 gevent自动异步了， 但我开发是在windows下，用不了gevent， 所以是 虚拟机里用 Ubuntu? 不然Ubuntu看着眼睛不太舒服。 单测 Python后端的话，是不是用 scrapy？

还想写通用爬虫， 更难了。

先把专业分清楚吧， 现在这个缺漏太多了。

## 20170918

自定义关键词的爬虫也基本没问题了， 不过研究方向太多，接下来需要处理下。

网站代码拆分， 不更新 zhimind库了， 分开装。

还有直接从主页怎么直接找到招生要求、 faculty目录的爬虫可以尝试着弄一个。

## 20170901

研究方向的爬虫能非常勉强的工作了
